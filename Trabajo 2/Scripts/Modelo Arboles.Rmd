---
title: "Model2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())
library(tidyverse)
library(randomForest)

ECM <- readRDS("../Funciones/ECM.rds")
R2 <- readRDS("../Funciones/R2.rds")
Result <- readRDS("../Funciones/Result.rds")
df <- readRDS("../Datos/data.rds")
```


## martes 

```{r}
f <- function(x){
  if(x<=10){
    y <- -(0.5*x-5)^2
  } else if (x>20){
    y <- (0.5*x-10)^2
  }else{
    y <- 0
  }
  return(y)
}
fv <- Vectorize(f)
```


```{r}
train <- df %>% mutate(dummy = fv(Mday)) %>%  filter(Date<"2017-07-01")
test <- df %>% mutate(dummy = fv(Mday)) %>%   filter(Date>="2017-07-01")  
```



## Regression mas tunin 

```{r}
library(AmesHousing)
library(rsample)     # data splitting 
library(dplyr)       # data wrangling
library(ranger)      # más rápida que randomforest
library(h2o) 
```



## default rf model 

```{r}
set.seed(123)

# default RF model
m1 <- randomForest(
  formula = Units ~ .,
  data    = train
)

m1
```

```{r}
# número de árboles con el menor MSE
which.min(m1$mse)
```
```{r}
sqrt(m1$mse[which.min(m1$mse)])
```




```{r}
# names of features
features <- setdiff(names(train), "Units")

set.seed(123)

m2 <- tuneRF(
  x          = train[features],
  y          = train$Units,
  ntreeTry   = 350,  # número de árboles
  mtryStart  = 5,    # valor inicial
  stepFactor = 1.5,  # factor de paso para incremento de mtry
  improve    = 0.01, # OBB error para si ha tenido una mejora del 1%
  trace      = TRUE  # 
)



```


```{r}
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 2),
  node_size  = seq(3, 9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)
nrow(hyper_grid)
```


```{r}
for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = Units ~ ., 
    data            = test, 
    num.trees       = 305,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123 # Notese el seteo de la semilla
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}


hyper_grid %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)
```



```{r}

train %>% select(Units, Year, Month,Wday, Mday, Yday,Holiday , dummy)-> train
model <- randomForest(
    formula         = Units ~. , 
    data            = train, 
    num.trees       = 300,
    mtry            = 5,
    min.node.size   = 5,
    sample.fraction = .8
  )


pred <- predict(model, test)
fit <- predict(model, train)

#test %>% mutate(predict = ifelse(Wday == "domingo" | Holiday == "1", 0, pred)) -> test
#train %>% mutate(fitted  = ifelse(Wday == "domingo" | Holiday == "1", 0, fit)) -> train

Result(fit, train$Units, pred, test$Units)

```













