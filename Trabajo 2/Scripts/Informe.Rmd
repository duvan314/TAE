---
title: "Predicción del número de vehículos registrados en el RUNT"
date: "11/01/2022"
author: 

- "David Santiago Espindola"
- "Duvan Camilo Manrique"
- "Jeison Durango"
- "Daniela vasco"
- "Valentina Agudelo"

output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```



```{r}
rm(list = ls())
library(reticulate)
library(tidyverse);library(lubridate);library(forecast);
library(car);library(TSA);library(FitAR);library(lmtest);
library(kableExtra);library(kableExtra); library(pander); 
library(randomForest);library(ranger);require(ISLR);require(glmnet)

ECM <- readRDS("../Funciones/ECM.rds")        # función ECM
R2 <- readRDS("../Funciones/R2.rds")          # funcion de R2
Result <- readRDS("../Funciones/Result.rds")            #
df <- readRDS("../Datos/data.rds")            # lectura de datos
```


# **Introducción**

$\hspace{1 cm}$

El Registro Único Nacional de Tránsito [RUNT](https://www.runt.com.co/Registros-runt), se define como un sistema de información que permite registrar y mantener actualizada, centralizada, autorizada y validada la misma sobre los registros de automotores, conductores, licencias de tránsito, empresas de transporte público, infractores, accidentes de tránsito, seguros, remolques y semirremolques, maquinaría agrícola y de construcción autopropulsada y de personas naturales o jurídicas que prestan servicio al sector(art. 8 y 9 de la Ley 769 de 2002 y la parte pertinente de la Ley 1005 de 2006).

En este trabajo se abordará el problema de crear un modelo para predecir el número de vehículos registrados diariamente en el RUNT. Los datos es una serie temporal del número de vehículos registrados diariamente durante los años 2012 a 2017. Para el análisis y modelamiento se incluyeron algunas variables que consideramos relevantes. En total, trabajaremos con un conjunto de datos que tiene **2192** observaciones y **9** variables. 


Los datos y el código que se uso en este trabajo se encuentra el siguiente repositorio [GitHub](https://github.com/duvan314/TAE/tree/main/Trabajo%202)

## **Variables**

Las variables que se considerarán para el modelo son las siguientes: 

$\hspace{1 cm}$

* *Units:* Número de vehículos registrados en el RUNT. 
* *Date:* Fecha *Año/Mes/Dia*.
* *Year:* Año.
* *Month:* Mes.
* *Wday:* Dia de la semana.
* *Mday:* Dia en el mes. 
* *Yday:* Dia en el año.
* *Holiday:* Indica si es festivo o no (1 para dia festivo).
* *Colombia:* Indica si ese dia la selección colombia jugó un partido oficial de la FIFA (1 si ese dia hubo partido). 

$\hspace{1 cm}$

Las primeras 7 variables se obtienen a partir de la base de datos suministrada. La variable [*Holiday*](https://calendariohispanohablante.com/2012/calendario-colombia-2012.html)  se incorporá ya que las instalaciones donde se hacen los trámites de registros del RUNT no laboran en días festivos. La variable [*Colombia*](www.futbolred.com/futbol-colombiano/liga-aguila/tablas-historicas-del-futbol-colombiano-62384) se agregó ya que esperamos que en estos días disminuya el número de registros. 

$\hspace{1 cm}$

## **Encabezado de la base de datos.** 

$\hspace{1 cm}$

```{r}
head(df) %>% 
  kable(digits = 5) %>%  
  kable_styling(font_size = 15)
```


```{python}
import pandas as pd
import pyreadr

result = pyreadr.read_r('../Datos/data.rds')
df = result[None]

```






# **Analisis descriptivo** 

Este módulo se presenta con la intención de poder entender los datos, identificar patrones y plantear hipótesis. 

$\hspace{1 cm}$


## **Dia de la semana y año**

### **Día de la semana y año**


### **Registros de vehiculos en el RUNT por día de la semana**

$\hspace{1 cm}$

```{r fig.width=12}

labs <- theme_light() +
  theme (plot.title = element_text(hjust = 0.5, size=rel(1.5), face="bold", lineheight=1.5, colour="gray0"))+
  theme(axis.title.x = element_text(face="bold", vjust=-0.5, colour="gray0", size=rel(1.3))) +
  theme(axis.title.y = element_text(face="bold", vjust=1.5, colour="gray0", size=rel(1.3))) 


df %>%  
  ggplot() + 
  geom_histogram(aes(Units, fill = Wday), alpha = 0.8)+ 
  scale_fill_manual(values = 2:8)+
  ggtitle("DIistribución de los registros RUNT") +
  labs(x = "Registros diarios",y = "Frecuencia") +
  labs-> p1

df %>%  
  ggplot() + 
  geom_boxplot(aes(Wday,Units, fill = Wday)) +
  scale_fill_manual(values = 2:8)+
  ggtitle("Registros RUNT por día de la semana") +
  labs(x = "Día de la semana",y = "Registros RUNT") +
  labs-> p2


gridExtra::grid.arrange(p1,p2, ncol = 2)
  

```

Durante los días martes a viernes no se presentan disimilitudes significativas en el número de registros, es evidente que el día sábado el número de registros disminuyen notablemente. Además, la mayoría de los registros del domingo son nulos. La caída de los registros del día lunes en comparación a los otros días de la semana podemos asociarlos a los festivos. Por último, para cada día de la semana se visualizan observaciones atípicas. 

$\hspace{1 cm}$

## **Registros de vehiculos en el RUNT por día y año**

$\hspace{1 cm}$

```{r  fig.width=12}

df %>%  mutate(Year = as.factor(Year)) %>% 
  ggplot() + geom_boxplot(aes(Year,Units,fill = Wday))+
  scale_fill_manual(values = 2:8)+
  ggtitle("REGISTROS RUNT POR DIA DE LA SEMANA Y AÑO") +
  labs(x = "Día de la semana",y = "Registros RUNT") +
  labs

```


Para cada año se observa el mismo comportamiento visto en el item anterior, sin embargo hay una tendencia decreciente en función del año. Las cajas de los primeros años obedecen a un mayor número de registros. 


### **Lo anterior mostrado en una tabla** 

$\hspace{1 cm}$


```{r, message=F, warning=FALSE}
df %>% group_by(Year, Wday) %>% 
  summarise(n = median(Units)) %>%
  spread(Wday, n) %>% kable(digits = 0, caption = "<center><strong>Mediana de Registros por año y día de la semana</strong></center>") %>%  
  kable_styling(font_size = 15)
```

$\hspace{1 cm}$

### **Desviación estándar de Registros por año y día de la semana** 


La siguiente tabla muestra la desviación estándar en el número de registros en función de los días de la semana y los años, se observa que el 2014 es el año con mayor variabilidad. 

$\hspace{1 cm}$

```{r}
df %>% group_by(Year, Wday) %>% 
  summarise(n = sd(Units)) %>% 
  spread(Wday, n) %>% kable(digits = 0, caption = "<center><strong>Desviación estándar de Registros por año y día de la semana</strong></center>") %>% kable_styling(font_size = 15)
```

$\hspace{1 cm}$

## **Registros durante mes y año**

$\hspace{1 cm}$

```{r fig.height=6, fig.width=15}

df %>% filter(Holiday == 0, Wday != "domingo") %>% 
  ggplot(aes(Mday,Units, color = Wday)) + geom_point() +
  geom_smooth(se = FALSE) + theme_light()+
    scale_fill_manual(values = 2:8)+
  ggtitle("Registros RUNT por día del mes") +
  labs(x = "Día del mes",y = "Registros RUNT") +
  labs-> p1

df %>% filter(Holiday == 0, Wday != "domingo") %>% 
  ggplot(aes(Yday,Units, color = Wday)) + geom_point() +
  geom_smooth(se = FALSE) + theme_light()+
    scale_fill_manual(values = 2:8)+
  ggtitle("Registros RUNT por día del año") +
  labs(x = "Día del año",y = "Registros RUNT") +
  labs-> p2

gridExtra::grid.arrange(p1,p2, ncol = 2)
```


En promedio la frecuencia de los registros de vehículos durante los primerios días del mes es más baja que durante los demás días. En contraste, la frecuencia promedio de los registros crece al final del mes. 

El comportamiento para los días durante el año es similar al de los días del mes, es baja al inicio, relativamente constante durante gran parte del año y alta al final. 

$\hspace{1 cm}$

## **Festivos**

Como se había previsto anteriormente, el número de registros los días festivos es bajo o nulo. En las siguientes tablas se muestran algunas estadísticas que prueban la hipótesis.

$\hspace{1 cm}$


### **Registros en dias festivos**

#### **Registros en días festivos**


$\hspace{1 cm}$




```{r}
df %>% group_by( Wday,Holiday) %>% summarise(n = mean(Units)) %>% spread(Holiday, n) %>% 
  rename("Dia Festivo" = "1", "Dia NO Festivo" = "0") %>% rename(Dia = Wday) %>% 
  kable(digits = 0,caption = "<center><strong>Media de Registros</strong></center>") %>%  
  kable_styling(font_size = 15)

```




### **Cuantiles de días Festivos**

#### **Cuantiles de días festivos**




```{r}
df %>% group_by( Wday,Holiday) %>%
  summarise(n = quantile(Units)) %>% mutate(Holiday = ifelse(Holiday == "1", "SI", "NO"))%>% 
  mutate(Cuantil = c("0 Q","1 Q", "2 Q", "3 Q", "4 Q")) %>% ungroup() %>% spread(Wday, n)%>% 
  rename(Festivo = Holiday) %>% 
  kable(digits = 0,caption = "<center><strong>Registros RUNT por día</strong></center>") %>%  
  kable_styling(font_size = 15)
  
```




 
# **Modelamiento**


Para la predicción de los registros de vehiculos diariamente en el RUNT consideramos 5 modelos:

- Modelo lineal.
- Modelo Poisson.
- Modelo Ridge.
- Modelo Lasso.


- Bosque aleatorio. 


Para escoger el mejor modelo usamos como métrica la comparación del $R^2$ de entreno y validación, es decir, 
$Min\{R^2_{train}/R^2_{Validation}\}$. Los datos de entrenamiento son los registros del *01/01/2012* a *31/12/2016*, validación los registros del 2017 y de prueba serán los datos del primer semestre del 2018. 


```{r}
df$Month <- as.factor(as.character(df$Month))
train <- df %>% filter(Date<"2017-01-01")
test <- df %>% filter(Date>="2017-01-01")
```



## **Modelo Lineal** 

El modelo a ajustar es el siguiente: 

$$\text{Units}_t = \beta_0+\beta_1\text{Yday}_t+\beta_2\text{Year}_t+\beta_{3}\text{Month}_{t}+
\beta_{4}\text{Wday}_{4}+\beta_5\text{Mday}_t+\beta_6\text{Holiday}_t+\beta_7\text{Colombia}_t + \epsilon_t$$


### **Resumen del modelo Lineal**

$\hspace{1 cm}$

```{r}

mod_lm <- lm(Units ~ Yday + Year + Month + Wday + Mday + Holiday + Colombia, data = train)
pander(summary(mod_lm))
```



## **Modelo Poisson**


El modelo a ajustar es el siguiente:

$$log(\text{Units}_t) = \beta_0+\beta_1\text{Yday}_t+\beta_2\text{Year}_t+\beta_{3,k}\text{Month}_{t,k}+
\beta_{4,k}\text{Wday}_{4,k}+\beta_5\text{Mday}_t+\beta_6\text{Holiday}_t+\beta_7\text{Colombia}_t$$



### **Resumen del modelo Poisson**

$\hspace{1 cm}$

```{r}

mod_po <-glm(Units ~ Yday+Year + Month + Wday + Mday + Holiday,data=train, family="poisson")
pander(summary(mod_po))


```




## **Modelo ridge**

#### **Modelo Ridge**



Para la estimación del modelo Ridge se minimiza $RSS_{Ridge}$ en función de los parámetros $\beta_j$. 

$$RSS_{Ridge}=\sum_{i=1}^n(y_i-f(x_i))^2+\lambda\sum_{i=1}^p\beta_j^2$$

donde: 

$$f(x_i) =\beta_0+\beta_1\text{Yday}_t+\beta_2\text{Year}_t+\beta_{3,k}\text{Month}_{t,k}+
\beta_{4,k}\text{Wday}_{4}+\beta_5\text{Mday}_t+\beta_6\text{Holiday}_t+\beta_7\text{Colombia}_t$$

$\hspace{1 cm}$


### **Coeficientes modelo Ridge**

$\hspace{1 cm}$

```{r}


x<-model.matrix(Units~.,df[,-1])[,-1]
y<-df$Units

x_train<- x[df$Date <"2017-01-01",]
x_test<- x[df$Date >="2017-01-01",]
y_train<- y[df$Date <"2017-01-01"]
y_test <- y[df$Date >="2017-01-01"]


gridz<-10^seq(-2,10, length=100)
ridge.mod<-glmnet(x_train,y_train,alpha= 0, lambda=gridz)


cv.out<-cv.glmnet(x_train, y_train, alpha=1)
bestlam<-cv.out$lambda.min
out<-glmnet (x,y,alpha=0)
ridge.coef<-predict(out,type="coefficients",s=bestlam)
data.frame(coef = ridge.coef[,1]) %>% 
  kable(digits = 5,caption = "<center><strong>Coeficientes Modelo Ridge</strong></center>") %>%  
  kable_styling(font_size = 15)
```



## **Modelo Lasso**

Para la estimación del modelo Lasso se minimiza $RSS_{Lasso}$ en función de los parametros $\beta_j$. 

$$RSS_{Lasso}=\sum_{i=1}^n(y_i-f(x_i))^2+\lambda\sum_{i=1}^p|\beta_j|$$

donde: 

$$f(x_i) =\beta_0+\beta_1\text{Yday}_t+\beta_2\text{Year}_t+\beta_{3}\text{Month}_{t}+
\beta_{4}\text{Wday}_{4}+\beta_5\text{Mday}_t+\beta_6\text{Holiday}_t+\beta_7\text{Colombia}_t$$

$\hspace{1 cm}$


### **Coeficientes modelo Lasso**

$\hspace{1 cm}$


```{r}
lasso.mod<-glmnet(x_train,y_train,alpha= 1, lambda=gridz)
cv.out<-cv.glmnet(x_train, y_train, alpha=1)
bestlam<-cv.out$lambda.min
out<-glmnet (x_train,y_train,alpha=1)
lasso.coef<-predict(out,type="coefficients",s=bestlam)

data.frame(coef = lasso.coef[,1]) %>% 
  kable(digits = 5,caption = "<center><strong>Coeficientes Modelo Lasso</strong></center>") %>%  
  kable_styling(font_size = 15)


```

$\hspace{1 cm}$

## **Residuos y ajuste**

### **Residuales**

A continuacón se presentan los residuos de cada uno de los modelos ajustados versus el tiempo. Al final de cada año todos los modelos presentan una mayor dispersión en el error de ajuste. Además, entre los años se observan ciertos picos, esto puede ser a causa de que a final de mes ocurren un mayor número de registros. Aunque los residuos de todos los modelos tienen un comportamiento similar, el modelo Poisson es el que presenta una menor variabilidad.  


$\hspace{1 cm}$

```{r fig.height=6, fig.width=12}

ridge_res <-y_train - predict(ridge.mod, s=bestlam,newx = x_train) 
lasso_res <-y_train - predict(lasso.mod, s=bestlam,newx = x_train)

par(mfrow = c(2,2))

plot(ts(residuals(mod_lm), frequency = 365, start = c(2012)), main = "Residuales vs el Tiempo (mod Lineal)", ylab = "Residuo", col = "red4")
plot(ts(residuals(mod_po), frequency = 365, start = c(2012)), main = "Residuales vs el Tiempo (mod Poisson)", ylab = "Residuo", col = "red4")
plot(ts(ridge_res, frequency = 365, start = c(2012)), main = "Residuales vs el Tiempo, (mod Ridge)", ylab = "Residuo", col = "red4")
plot(ts(lasso_res, frequency = 365, start = c(2012)), main = "Residuales vs el Tiempo (mod Lasso)", ylab = "Residuo", col = "red4")

```
$\hspace{1 cm}$


### **Registros RUNT vs Predicciones** 

$\hspace{1 cm}$

```{r fig.height=6, fig.width=12}
pred <- predict(mod_lm, test)
fit <- fitted(mod_lm)
real <- test$Units
resul_lm <- Result(fit, train$Units, pred, test$Units)
R2_lm <- c(R2(fit, train$Units),R2(pred, test$Units), R2(fit, train$Units)/R2(pred, test$Units))


train %>% select(Units) %>% 
  mutate(Predict = fit, data = "train") %>% 
  rbind(test %>% select(Units) %>% mutate(Predict = pred, data = "test")) %>% 
  ggplot() + geom_point(aes(Units, Predict, color = data)) +
    ggtitle("Predicción vs Real (mod Lineal)") +geom_abline(intercept = 0)+
  labs-> p1


pred <- predict(mod_po, test,  type="response") 
fit <- predict(mod_po, train,  type="response")
resul_po <- Result(fit, train$Units, pred, test$Units)

R2_po <- c(R2(fit, train$Units),R2(pred, test$Units), R2(fit, train$Units)/R2(pred, test$Units))

train %>% select(Units) %>% 
  mutate(Predict = fit, data = "train") %>% 
  rbind(test %>% select(Units) %>% mutate(Predict = pred, data = "test")) %>% 
  ggplot() + geom_point(aes(Units, Predict, color = data)) +
  ggtitle("Predicción vs Real (mod Poisson)") +geom_abline(intercept = 0)+
  labs -> p2


pred <- predict(ridge.mod, s=bestlam,newx= x_test)
fit <- predict(ridge.mod, s=bestlam,newx= x_train)


R2_Rd <- c(R2(fit[,1], y_train),R2(pred[,1], y_test), R2(fit[,1], y_train)/R2(pred[,1], y_test))
train %>% select(Units) %>% 
  mutate(Predict = fit, data = "train") %>% 
  rbind(test %>% select(Units) %>% mutate(Predict = pred, data = "test")) %>% 
  ggplot() + geom_point(aes(Units, Predict, color = data)) +
  ggtitle("Predicción vs Real (mod Ridge)") +geom_abline(intercept = 0)+
  labs -> p3


pred <- predict(lasso.mod, s=bestlam,newx= x_test)
fit <- predict(lasso.mod, s=bestlam,newx= x_train)

R2_Ls <- c(R2(fit[,1], y_train),R2(pred[,1], y_test), R2(fit[,1], y_train)/R2(pred[,1], y_test))

train %>% select(Units) %>% 
  mutate(Predict = fit, data = "train") %>% 
  rbind(test %>% select(Units) %>% mutate(Predict = pred, data = "test")) %>% 
  ggplot() + geom_point(aes(Units, Predict, color = data)) +
  ggtitle("Predicción vs Real (mod Lasso)") + geom_abline(intercept = 0)+
  labs -> p4

gridExtra::grid.arrange(p1,p2,p3,p4, ncol = 2)

```




- En general, para registros inferiores a 1500 todos los modelos presentan una sobreestimación, especialmente en el conjunto de validación. Por otro lado para las observaciones atipicas las predicciones generalmente son inferiores a los valores reales. 

- En general, para registros inferiores a 1500 todos los modelos presentan una sobreestimación, especialmente en el conjunto de validación. Por otro lado, para las observaciones atípicas las predicciones generalmente son inferiores a los valores reales. 

- Los modelos Lineal, Ridge y Lasso hacen predicciones negativas, las cuales dado el contexto del problema no son posibles. 
- Por lo anterior, el modelo Poisson es adecuado para la predicción de los registros en el RUNT. 

$\hspace{1 cm}$


## **Metricas** 

#### **Métricas** 


Como se esperaba, el modelo Poisson es el que mejor ajuste tiene, con el se obtiene un mayor $R^2$ tanto en entreno como en validación. Además, tiene el menor cociente $R^2_{Train}/R^2_{Validation}$. 

$\hspace{1 cm}$

```{r}
R2s <- rbind(R2_lm,R2_po,R2_Rd,R2_Ls)
colnames(R2s) <- c("Train", "Validation", "Ratio")
rownames(R2s) <- c("Lineal", "Poisson", "Ridge", "Lasso")
R2s%>% 
  kable(digits = 5,caption = "<center><strong>$R^2$ de entreno y prueba</strong></center>") %>%  
  kable_styling(font_size = 15)

```








## **Mejorando el modelo Poisson**

Dado que el Poisson fue el mejor modelo, se agregará una nueva variable con la intención de disminuir la brecha entre el $R^2$ de entreno y validación. 

$\hspace{1 cm}$

### **Variable dummy**

Considrando que durante los primeros días del mes los registros en el RUNT son bajos y al final de mes son altos, se crea una función que capture este comportamiento. En este sentido, para la varaible $**\text{Mday}**$ se le aplicará la siguiente función. 

$\hspace{1 cm}$

$$f(\text{x})= \left\{ \begin{array}{lcc}
             -(0.5x-5)^2 &   si  & x \leq 10 \\
             \\ 0 &  si & 10 < x < 21\\
             \\ (0.5x-10)^2 &  si  & x \geq 21
             \end{array}
   \right.$$


$\hspace{1 cm}$


```{r}
fv <- readRDS("../Funciones/dv_dummy.rds")
plot(ts(fv(1:31)), main = "Comportamiento de variable Dummy", xlab = "Día del mes",ylab= "Valor Dummy", col = "blue4")
```



## **Modelo Poisson con la nueva variable**


El modelo a ajustar es el siguiente:

$$log(\text{Units}_t) = \beta_0+\beta_1\text{Yday}_t+\beta_2\text{Year}_t+\beta_{3,k}\text{Month}_{t,k}+
\beta_{4,k}\text{Wday}_{4,k}+\beta_5\text{Mday}_t+\beta_6\text{Holiday}_t+\beta_8\text{Dummy}_t$$


### **Resumen del modelo**

$\hspace{1 cm}$

```{r fig.width=15}
df <- df %>% mutate(Max = ifelse(Mday>29, "1", "0")) %>% 
  mutate(Max2 = ifelse(Yday>364, "1", "0")) %>% 
  mutate(Max = ifelse(Holiday == "1","0", Max),
         Max = ifelse(Wday == "domingo","0",Max),
         Max2 = ifelse(Holiday == "1","0", Max2),
         Max2 = ifelse(Wday == "domingo","0",Max2),
         dummy = fv(Mday))

train <- df %>% filter(Date<"2017-01-01")
test <- df %>% filter(Date>="2017-01-01") 


mod_po2 <-glm(Units ~ Yday+Year + Month + Wday + Mday + Holiday+dummy,data=train, family="poisson")



pander(summary(mod_po))

fit <- fitted(mod_po2)
pred <- predict(mod_po2, test,  type="response")


```


### **Comparando los dos modelos Poisson**

Al ajustar el modelo Poisson con una variable dummy, visualmente se aprecia una reducción en la varianza. Sin embargo, aun el modelo se equivoca el resultado de final de año.

```{r fig.height=6, fig.width=15}
par(mfrow = c(1,2))
plot(ts(residuals(mod_po), frequency = 365, start = c(2012)), 
     main = "Residuales vs el Tiempo (mod Lineal)",
     ylab = "Residuo", col = "red4", ylim = c(-40,40))
plot(ts(residuals(mod_po2), frequency = 365, start = c(2012)), 
     main = "Residuales vs el Tiempo (mod Poisson 2)", 
     ylab = "Residuo", col = "red4", ylim = c(-40,40))
```



## **ECM y R2 para el modelo Poisson**

Al agregar la variable dummy al modelo se consigue mejorar el $R2$ de validación, sim embargo se baja en un $2\%$ el $R^2$ de entreno. además, la nueva variable logra disminuir el ratio $Min\{R^2_{train}/R^2_{Validation}\}$.


train %>% select(Units) %>% 
  mutate(Predict = fit, data = "train") %>% 
  rbind(test %>% 
          select(Units) %>% 
          mutate(Predict = pred, data = "test")) %>% 
  ggplot() + geom_point(aes(Units, Predict, color = data)) +
  geom_abline(intercept = 0) +
  ggtitle("Prediccion vs Real (mod Poisson con dummy)") +
  labs -> p3


```{r}

fit <- fitted(mod_po2)
pred <- predict(mod_po2, test,  type="response")
Result(fit,
       train$Units,
       pred, test$Units)

```





# **modelo Residuos**

Al ser una serie de tiempo, se espera que haya un comportamiento estacional y posible correlación entre los errores. además, se observa que el modelo no es capaz de capturar los finales de año y sospechamos que al final de algunos meses. Inicialmente se propone un modelo autorregresivo (no se encuentra en este trabajo) para los residuos, sin embargo, estos modelos pierden precisión cuando se quiere predecir en un horizonte temporal alto a largo plazo. En este sentido se propone un modelo de bosques aleatorios para modelar los residuos y poder tener una mayor precisión en el conjunto de validación y de prueba. Con esto se quiere modelar la estacionalidad y no la autocorrelación.


```{r}
par(mfrow=c(1,2))
plot(ts(residuals(mod_po2), frequency = 365, start = c(2012)), main = "Residuales vs el Tiempo (mod Poisson2)", ylab = "Residuo", col = "red4")
acf(ts(residuals(mod_po2)),main = "ACF de los residuos (mod Poisson2)")
```

## Escogiendo los parametros de randomForest.

Se usará la función `randomForest::randomForest()`. Esta funcion tiene varios hiper-parámetros , pero en este caso solo ajustaremos tres:

* `mtry`
* `node_size`
* `sampe_size`


```{r}

train_res <- train %>% mutate(res = Units-fit) %>% select(-Units, -Date, - Colombia)
test_res <- test %>% mutate(res = Units - pred) %>% select(-Units, -Date, - Colombia)

set.seed(123)

# default RF model
hyper_grid_res <- expand.grid(
  mtry       = seq(3,7, by = 2),
  node_size  = seq(3, 9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

set.seed(123)

for(i in 1:nrow(hyper_grid_res)) {
  
  # train model
  model <- ranger(
    formula         = res ~ ., 
    data            = test_res, 
    num.trees       = 305,
    mtry            = hyper_grid_res$mtry[i],
    min.node.size   = hyper_grid_res$node_size[i],
    sample.fraction = hyper_grid_res$sampe_size[i],
    seed            = 123 # Notese el seteo de la semilla
  )
  
  # add OOB error to grid
  hyper_grid_res$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

hyper_grid_res %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(2)


```

## Resultados con Random Forest. 

Modelando los residuos se puede capturar algunos comportamientos y patrones que no fueron posibles percibir con el modelo `Poisson`, esto se puede probar con los resultados de la siguiente tabla. Pues el valor del $R^2$ de validación solo supera en un $3.3\%$ el de entreno.  


```{r}



m1 <- randomForest(
    formula         = res ~. , 
    data            = train_res, 
    num.trees       = 300,
    mtry            = 7   ,
    min.node.size   = 7,
    sample.fraction = 0.632	
  )

pred_res_t <- predict(m1, train_res)
pred_res   <- predict(m1, test_res)




p_t <- ifelse(train$Holiday=="1" |train$Wday =="domingo", 0, fit)
p_t <- ifelse(p_t<1, 0, p_t)
p <- ifelse(pred+pred_res<1, 0, pred+pred_res)
p <- ifelse(test$Holiday=="1" |test$Wday =="domingo", 0, p)

Result(p_t, train$Units,p , test$Units)
```

## modelo definitivo

El modelo con el cual consideramos que y el cual nos servirá para modelar los vehículos inscritos en el RUNT será: 


$$log(\text{Units}_t) = \beta_0+\beta_1\text{Yday}_t+\beta_2\text{Year}_t+\beta_{3,k}\text{Month}_{t,k}+
\beta_{4,k}\text{Wday}_{4,k}+\beta_5\text{Mday}_t+\beta_6\text{Holiday}_t+\beta_8\text{Dummy}_t+\epsilon_t$$

Donde $\epsilon_t$ se modela con un bosque aleatorio y así corregir algunos patrones de estacionalidad que no logra capturar el modelo de regresión Poisson. además, considerando la naturaleza de los datos y dado que durante días festivos y domingos el número de registros es casi nulo en la mayoría de casos, independiente del valor que predijo esos días los volveremos ceros. 

## Predicción. 

A continuación, se presenta la comparación en la distribución de las predicciones. los resultados de estas se pueden consultar el siguiente link.

```{r}

df_train <- df %>% mutate(dummy = fv(Mday)) %>% select(-Max, -Max2)

mod_po <-glm(Units ~ Yday+Year + Month + Wday + Mday + Holiday + dummy,data=df_train, family="poisson")


fit <- fitted(mod_po)    
df_test <- readRDS("../Datos/data_2018.rds") %>% mutate(dummy = fv(Mday))

rbind(df_train %>% mutate(res = round(Units-fit,4)) %>% 
        select(-Units, -Date, - Colombia), df_test %>% select( -Date, - Colombia) %>% mutate(res = 0))-> df_res


set.seed(12)

m1 <- randomForest(formula= res ~Holiday+Year+Month+Wday+Mday+Yday+dummy , data= df_res[df_res$Year<2018,], num.trees= 100,
                   mtry= 7,min.node.size= 5,sample.fraction = 0.8)

pred_res <- predict(m1, df_res[df_res$Year==2018,])


prediccion_17 <- fitted(mod_po)
p_2018 <- predict(mod_po, df_test,  type="response") + pred_res
prediccion_18 <- ifelse(p_2018 < 2, 0,p_2018)

df_test %>% mutate(prediccion_18) %>%
  mutate(prediccion_18 = ifelse(Wday == "domingo" | Holiday =="1", 0, prediccion_18)) -> pre_8


prediccion_2018 <- data.frame(Fecha = df_test$Date, Prediccion = pre_8$prediccion_18)
prediccion_12_17 <- data.frame(Fecha = df_train$Date, Prediccion = prediccion_17)

write.table(prediccion_2018, file =  "../Predicciones/prediccion_2018.txt", sep = "," ,row.names = FALSE)
write.table(prediccion_12_17, file = "../Predicciones/prediccion_12_17.txt", sep = ",",row.names = FALSE)


prediccion_2018 %>% mutate(Data = "Test") %>%
  rbind(prediccion_12_17 %>% mutate(Data = "Train")) %>% ggplot() +
  geom_histogram(aes(Prediccion, fill = Data))

```


# **Referencias**





- Registro Único Nacional de Tránsito.(2009 - 2021). https://www.runt.com.co/Registros-runt
- Anónimo. (2015-2020). https://calendariohispanohablante.com/2012/calendario-colombia-2012.html.
- Anónimo. www.futbolred.com/futbol-colombiano/liga-aguila/tablas-historicas-del-futbol-colombiano-62384
- https://rpubs.com/duvan/InscipcionesRUNTTAE



















